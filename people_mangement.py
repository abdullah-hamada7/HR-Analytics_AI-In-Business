# -*- coding: utf-8 -*-
"""People Mangement

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QvJdwo0BWFABUs_tffoIl6uwGIscAfeU

**What Business Domain Does This Serve?
This is clearly from a corporate HR analytics system, supporting:**

üë®‚Äçüíº Workforce Planning

üí∞ Compensation & Salary Strategy

üöÄ Promotion Path & Talent Development

üè¢ Departmental Allocation

üßë‚Äç‚öñÔ∏è Manager Effectiveness

üìä Gender Equity and Diversity Monitoring

## Employee Data
"""

import pandas as pd

dfE = pd.read_csv("employee.csv")
dfE.head()

# 1. Describe (categorical data)
print(dfE.describe(include='object'))

# 2. Info
print(dfE.info())

# 3. Null values
print(dfE.isnull().sum())

# 4. Duplicates
print(f"Duplicate rows: {dfE.duplicated().sum()}")

# 5. Data Validation
print(f"Unique first names: {dfE['first_name'].nunique()}")
print(f"Unique last names: {dfE['last_name'].nunique()}")

"""## Dep_Employee"""

import pandas as pd

dfDE = pd.read_csv("department_employee.csv")
dfDE.head()

# 1. Describe (categorical data)
print(dfDE.describe(include='object'))

# 2. Info
print(dfDE.info())

# 3. Null values
print(dfDE.isnull().sum())

# 4. Duplicates
print(f"Duplicate rows: {dfDE.duplicated().sum()}")

# 5. Data Validation
print(f"Unique departments: {dfDE['department_id'].nunique()}")
print(f"Unique employees: {dfDE['employee_id'].nunique()}")

"""## Dep Data"""

import pandas as pd

dfD = pd.read_csv("department.csv")
dfD.head()

# 1. Describe (categorical data)
print(dfD.describe(include='object'))

# 2. Info
print(dfD.info())

# 3. Null values
print(dfD.isnull().sum())

# 4. Duplicates
print(f"Duplicate rows: {dfD.duplicated().sum()}")

# 5. Data Validation
print(f"Unique departments: {dfD['dept_name'].nunique()}")

"""## Salary Data"""

import pandas as pd

dfS = pd.read_csv("salary.csv")
dfS.head()

# 1. Describe (categorical data)
print(dfS.describe(include='object'))

# 2. Info
print(dfS.info())

# 3. Null values
print(dfS.isnull().sum())

# 4. Duplicates
print(f"Duplicate rows: {dfS.duplicated().sum()}")

# 5. Data Validation
print(f"Unique departments: {dfS['employee_id'].nunique()}")

"""## Department_manager Data"""

import pandas as pd

dfDM = pd.read_csv("department_manager.csv")
dfDM.head()

print(dfDM.describe(include='object'))

# 2. Info
print(dfDM.info())

# 3. Null values
print(dfDM.isnull().sum())

# 4. Duplicates
print(f"Duplicate rows: {dfDM.duplicated().sum()}")

# 5. Data Validation
print(f"Unique departments: {dfDM['department_id'].nunique()}")
print(f"Unique employees: {dfDM['employee_id'].nunique()}")

"""## Title Data

"""

import pandas as pd

dfT = pd.read_csv("title.csv")
dfT.head()

print(dfT.describe(include='object'))
print(dfT.info())
print(dfT.isnull().sum())
print(f"Duplicate rows: {dfT.duplicated().sum()}")
print(f"Unique titles: {dfT['title'].nunique()}")

"""## Current_employee_snapshot Data




"""

import pandas as pd

dfCE = pd.read_csv("current_employee_snapshot.csv")
dfCE.head()

print(dfCE.describe(include='object'))
print(dfCE.info())
print(dfCE.isnull().sum())
print(f"Duplicate rows: {dfCE.duplicated().sum()}")



"""**Cases Study Invistgation.**"""

#1."Which departments are best at keeping their employees for many years?"-> Calculate the average employee tenure (years worked) for each department.

'''
average tenure per department using:

employee.csv ‚Üí employee ID and hire date

department_employee.csv ‚Üí department history

department.csv ‚Üí department names
'''

'''
If a department retains employees longer, it might mean:

Good management

Healthy work culture

Better job satisfaction

Employees are more engaged or loyal to the company

'''

import pandas as pd
from datetime import datetime

# Load and parse dates, handling '9999-01-01'
dfE['hire_date'] = pd.to_datetime(dfE['hire_date'])
dfDE['from_date'] = pd.to_datetime(dfDE['from_date'])
dfDE['to_date'] = dfDE['to_date'].replace('9999-01-01', pd.NaT)
dfDE['to_date'] = pd.to_datetime(dfDE['to_date'])

# Today's date for tenure calculation
today = pd.Timestamp(datetime.today())

#SQL
# Step 1: Merge employees with their department assignments
emp_dept = pd.merge(dfDE, dfE, left_on='employee_id', right_on='id', how='left')

'''
dfDE: contains department assignments ‚Üí has employee_id, department_id, from_date, to_date

dfE: contains employee info ‚Üí has id, hire_date, gender, etc.
'''

# Step 2: Calculate employee total tenure (years)
emp_dept['tenure_years'] = (today - emp_dept['hire_date']).dt.days // 365

# Step 3: Use most recent assignment only (to avoid duplication)
emp_dept_latest = emp_dept.sort_values('from_date').drop_duplicates('employee_id', keep='last')

# Step 4: Merge with department names
emp_dept_named = pd.merge(emp_dept_latest, dfD, left_on='department_id', right_on='id', how='left')

# Step 5 (Updated): Group by department and compute both average tenure and employee count
dept_summary = emp_dept_named.groupby('dept_name').agg(
    average_tenure_years=('tenure_years', 'mean'),
    employee_count=('employee_id', 'nunique')
).sort_values(by='average_tenure_years', ascending=False)

# Step 6: Show results
print("\nüìä Department Summary (Average Tenure + Employee Count):")
print(dept_summary)

# Optional: Bar Plot
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
dept_summary.plot(kind='barh', color='steelblue')
plt.title("Average Tenure by Department")
plt.xlabel("Years")
plt.gca().invert_yaxis()
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

#2. Find the department with the highest total salary payout (sum of salaries of current employees)?

'''
My steps of thinking to solve this problem?

1:  Merges salary table with employee info to get `hire_date`, etc.
2 : Keeps **only the most recent salary** for each employee.
3 : Merges with their **most recent department** assignment.
4 : Merges to get the **department names**.
5 : Groups by `dept_name` and **sums up salaries**.
6‚Äì7: Shows the department with the **highest salary payout**.

'''

dfS.columns

# Step 1: Merge salaries with employee info
emp_salary = pd.merge(dfS, dfE, left_on='employee_id', right_on='id', how='left')

# Step 2: Filter most recent salary entry for each employee
emp_salary_latest = emp_salary.sort_values('to_date').drop_duplicates('employee_id', keep='last')

# Step 3: Merge with latest department assignment
emp_dept_salary = pd.merge(emp_salary_latest, emp_dept_latest, on='employee_id', how='left')

# Step 4: Merge with department names
emp_dept_salary_named = pd.merge(emp_dept_salary, dfD, left_on='department_id', right_on='id', how='left')

# Step 5: Group by department name and sum salaries
dept_salary_total = emp_dept_salary_named.groupby('dept_name')['amount'].sum().sort_values(ascending=False)

# Step 6: Display result
print("\nüí∞ Total Salary Paid per Department:")
print(dept_salary_total)

# Step 7: Get top department
top_salary_dept = dept_salary_total.idxmax()
top_salary_value = dept_salary_total.max()

print(f"\nüèÜ Department with Highest Salary Payout: {top_salary_dept} (${top_salary_value:,.2f})")

import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Reset index to convert Series to DataFrame
dept_salary_total_df = dept_salary_total.reset_index()
dept_salary_total_df.columns = ['Department', 'Total Salary']

# Step 2: Set visual style
plt.figure(figsize=(12, 6))
sns.set(style="whitegrid")

# Step 3: Bar plot
sns.barplot(
    data=dept_salary_total_df,
    x='Total Salary',
    y='Department',
    palette='viridis'
)

# Step 4: Add value labels
for index, value in enumerate(dept_salary_total_df['Total Salary']):
    plt.text(value + 1000, index, f"${value:,.0f}", va='center')

# Step 5: Titles and labels
plt.title("üí∞ Total Salary Paid per Department", fontsize=16)
plt.xlabel("Total Salary (USD)")
plt.ylabel("Department")

# Step 6: Show plot
plt.tight_layout()
plt.show()

#1.  Top 10 Highest Paid Employees per Department
import plotly.express as px

dfCE.info()
res=dfCE.sort_values(['dept_name', 'salary_amount'], ascending=[True, False]).groupby('dept_name').head(10).reset_index(drop=True)
res.head(10)

res['employee_id'] = res['employee_id'].astype(str)

fig = px.bar(
    res,
    x='salary_amount',
    y='employee_id',
    color='dept_name',
    orientation='h',
    title='Top 10 Highest Paid Employees per Department',
    labels={
        'salary_amount': 'Salary',
        'employee_id': 'Employee ID',
        'dept_name': 'Department'
    },
    hover_data=['title', 'gender', 'company_tenure', 'dept_name']
)

fig.show()

#2.  Salary Growth Analysis Over Time
dfS['from_date'] = pd.to_datetime(dfS['from_date'])

dfS['year'] = dfS['from_date'].dt.year

avg_salary_per_year = (
    dfS.groupby('year')['amount']
    .mean()
    .reset_index()
    .sort_values('year')
)

fig = px.line(
    avg_salary_per_year,
    x='year',
    y='amount',
    markers=True,
    title='Average Salary Growth Over Time',
    labels={'year': 'Year', 'amount': 'Average Salary'}
)
fig.show()

#3.  Departments with High Turnover
res=dfCE.groupby('dept_name')['department_tenure'].mean().reset_index().sort_values('department_tenure')

fig = px.bar(
    res,
    x='dept_name',
    y='department_tenure',
    title='Departments with Highest Turnover',
    labels={
        'dept_name': 'Department',
        'department_tenure': 'Average Department Tenure (Years)'
    },
    color='department_tenure',
    color_continuous_scale='Reds'
)
fig.show()
'''Goal: Identify departments where employees tend to leave (short tenure).

Impact: Red flag for toxic culture or bad management.'''

gender_dist = (
    dfCE.groupby(['dept_name', 'gender'])
    .size()
    .reset_index(name='count')
)

res = px.bar(
    gender_dist,
    x='dept_name',
    y='count',
    color='gender',
    title='Gender Distribution per Department',
    barmode='group',
    labels={'dept_name': 'Department', 'count': 'Employee Count'}
)
res.show()

dept_counts = dfCE['dept_name'].value_counts().reset_index()
dept_counts.columns = ['dept_name', 'employee_count']

res = px.bar(
    dept_counts,
    x='dept_name',
    y='employee_count',
    title='Employee Count per Department',
    labels={'dept_name': 'Department', 'employee_count': 'Employees'},
    color='employee_count',
    color_continuous_scale='Blues'
)
res.show()

res = px.histogram(
    dfCE,
    x='salary_amount',
    nbins=50,
    title='Salary Distribution (Current Employees)',
    labels={'salary_amount': 'Salary'},
    color_discrete_sequence=['#636EFA']
)
res.show()

title_tenure = (
    dfCE.groupby('title')['company_tenure']
    .mean()
    .reset_index()
    .sort_values('company_tenure')
)

res = px.bar(
    title_tenure,
    x='company_tenure',
    y='title',
    orientation='h',
    title='Average Company Tenure by Job Title',
    labels={'company_tenure': 'Avg Tenure (Years)', 'title': 'Job Title'},
    color='company_tenure',
    color_continuous_scale='Viridis'
)
res.show()

fig9 = px.box(
    dfCE,
    x='dept_name',
    y='salary_amount',
    title='Salary Distribution by Department',
    labels={'dept_name': 'Department', 'salary_amount': 'Salary'},
    color='dept_name',
)
fig9.update_layout(xaxis_tickangle=-45)
fig9.show()

title_gender = (
    dfCE.groupby(['title', 'gender'])
    .size()
    .reset_index(name='count')
    .sort_values('count', ascending=False)
)

fig = px.bar(
    title_gender,
    x='title',
    y='count',
    color='gender',
    barmode='group',
    title='Title Distribution by Gender',
    labels={'title': 'Job Title', 'count': 'Employee Count'}
)
fig.update_layout(xaxis_tickangle=-45)
fig.show()

print(dfCE[dfCE['title'] == 'Manager']['gender'].value_counts())

dfE['hire_year'] = pd.to_datetime(dfE['hire_date']).dt.year

hire_counts = dfE['hire_year'].value_counts().sort_index().reset_index()
hire_counts.columns = ['hire_year', 'employee_count']

res = px.line(
    hire_counts,
    x='hire_year',
    y='employee_count',
    title='Employees Hired per Year',
    markers=True,
    labels={'hire_year': 'Year', 'employee_count': 'Hires'}
)
res.show()

dept_title_salary = (
    dfCE.groupby(['dept_name', 'title'])['salary_amount']
    .mean()
    .reset_index()
)

res = px.bar(
    dept_title_salary,
    x='dept_name',
    y='salary_amount',
    color='title',
    barmode='group',
    title='Average Salary by Department and Title',
    labels={'salary_amount': 'Avg Salary', 'dept_name': 'Department'}
)
res.update_layout(xaxis_tickangle=-45)
res.show()

dfCE['company_tenure'].value_counts()

df_model = dfCE.copy()
df_model['attrition_risk'] = (df_model['company_tenure'] < 13).astype(int)

numerical = [
    'salary_amount',
    'salary_percentage_change',
    'department_tenure',
    'title_tenure'
]

categorical = ['gender', 'title', 'dept_name']
features = numerical + categorical

X = df_model[features]
y = df_model['attrition_risk']

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score

X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.2, random_state=42
)

preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numerical),
    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical)
])

models = {
    'Logistic': LogisticRegression(max_iter=1000),
    'RandomForest': RandomForestClassifier(),
    'GradientBoosting': GradientBoostingClassifier(),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss')
}

for name, model in models.items():
    clf = Pipeline([
        ('preprocess', preprocessor),
        ('model', model)
    ])
    clf.fit(X_train, y_train)
    y_proba = clf.predict_proba(X_test)[:,1]
    auc = roc_auc_score(y_test, y_proba)
    print(f"{name}: AUC = {auc:.3f}")

clf = Pipeline(steps=[
    ('preprocess', preprocessor),
    ('model', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42))
])

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred, digits=3))

import joblib
joblib.dump(clf, 'retention_model.pkl')